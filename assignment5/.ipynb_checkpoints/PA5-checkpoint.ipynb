{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aai6gZ-4_Xx"
   },
   "source": [
    "# Programming Assignment 5 - Build your own Conventional Neural Network\n",
    "\n",
    "After completing this project, you will be able to do the following:\n",
    "\n",
    "- Build neural network conveniently.\n",
    "- Configure with different regularization methods: Dropout, l1 or l2 regulation.\n",
    "\n",
    "- **574 Only**: Fine tune pre-trained model to build your own projects.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "This dataset is provided by our current research project, which utilize 20 kHz acoustic sensing to sense ASL gestures. All the 10 ASL words perform by 5 subjects. All images are generated by using the short-time Fourier transform (STFT) to calculate a spectrogram as the feature representation of the reflected near-ultrasound waves. Based on the Doppler effect, sign language gestures, including both hands and arms, will cause phase and frequency changes of the reflected sonic wave. The spectrogram contains information in both frequency and time domains. The spectrogram is also defined as the Power Spectral Density of the function:\n",
    "\\begin{equation}\n",
    "    \\textrm{spectrogram}\\{x(t)\\}(\\tau,\\omega)\\equiv |X(\\tau,\\omega)|^{2}= \\left| \\sum^{\\infty}_{n=-\\infty}x[n]\\omega[n-m]e^{-j\\omega n}\\right|^{2}\n",
    "\\end{equation}\n",
    "where $x[n]$ is input signal, and $\\omega[n-m]$ represents the overlapping Kaiser window function with an adjustable shape factor $\\beta$ that improves the resolution and reduces the spectral leakage close to the sidelobes of the signal. The coefficients of the Kaiser window are computed as:\n",
    "\\begin{equation}\n",
    "    \\omega[n]=\\frac{I_{0}\\left(\\beta\\sqrt{1-\\left(\\frac{n-N/2}{N/2}\\right)^{2}}\\right)}{I_{0}(\\beta)}, 0 \\leq n \\leq N\n",
    "\\end{equation}\n",
    "\n",
    "This dataset has a training set of 5,000 examples, and a test set of 1,000 examples.\n",
    "\n",
    "# Submission\n",
    "\n",
    "1. **Coding checks (60 points)** - The code for your implementation should be in Python only. The name of the Main file should be main.ipynb or main.py. Please provide necessary comments in the code.\n",
    "\n",
    "2. **Written Report (40 points)**: The report should be delivered as a separate pdf file, and it is recommended for you to use the NIPS template to structure your report. You may include comments in the Jupyter Notebook, however you will need to duplicate the results in the report. The report should describe your results, experimental setup and comparison between the results obtained\n",
    "from different setting of the algorithm and dataset.**Again, the questions in the Assignment PDF and here are the same (for the written report), we just put them in both places for convenience.**\n",
    "\n",
    "\n",
    "As such, you will submit, one member of your group will subit as a zip file on UBLearns, a ```.zip``` file that contains 3 things:\n",
    "- Your completed jupyter notebook.\n",
    "- Your written report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ZIpD7t5-4_X1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## please add the essential libraries\n",
    "\n",
    "# YOUR CODE HERE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DOyaRk7oByu"
   },
   "source": [
    "## Part 1. loading dataset\n",
    "\n",
    "We have splitted the dataset into training, validation and test. You can load every single folder to load dataset using keras ImageDataGenerator (10 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "FvcmLd5V4_X8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4176 images belonging to 10 classes.\n",
      "Found 1392 images belonging to 10 classes.\n",
      "Found 1392 images belonging to 10 classes.\n",
      "(16, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# load the file from our dataset including training, validation and testing part\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir      = 'pictures/train'\n",
    "validation_data_dir = 'pictures/val'\n",
    "test_data_dir       = 'pictures/test'\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "# # this is a generator that will read pictures found in\n",
    "# # subfolers of 'data/train', and indefinitely generate\n",
    "# # batches of augmented image data\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zca_epsilon=1e-06,\n",
    "#     rotation_range=0.2,\n",
    "#     width_shift_range=0.05,\n",
    "#     height_shift_range=0.05,\n",
    "#     shear_range=0.05,\n",
    "#     zoom_range=0.05,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "# Your Code HERE\n",
    "\n",
    "train_datagen = datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
    "train_images, train_labels = next(train_datagen)\n",
    "\n",
    "#valid_generator = \n",
    "val_datagen = datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
    "val_images, val_labels = next(val_datagen)\n",
    "\n",
    "# test_generator  = \n",
    "test_datagen = datagen.flow_from_directory(test_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
    "test_images, test_labels = next(test_datagen)\n",
    "\n",
    "# please print the number of samples in each folder \n",
    "# Your Code HERE\n",
    "train_sample = train_datagen.samples\n",
    "val_sample = val_datagen.samples\n",
    "test_sample = test_datagen.samples\n",
    "\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwuT9Fr24_X9"
   },
   "source": [
    "## Part 2.1 - Build your Neural Network and Train\n",
    "\n",
    "Build a Convolutional Neural Network with 2 or 3 hidden layers without regularization methods, which includes Conv2D layer, activation Layer. please use training dataset and validation dataset for training processs, and plot the training process with Loss trend and accuracy trend (30 Points).\n",
    "\n",
    "## Part 2.2 - Test \n",
    "\n",
    "Test your machine learning model on the testing set: After finishing all the above steps, fix your hyper-parameters(learning rate, number of neurons per layer) and model parameter and test your model’s performance on the testing set. This shows the effectiveness of your model’s generalization power gained by learning. For test dataset, the performance should be more than 80% (10 Points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "d18BuhN34_X-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (224, 224, 3)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 111, 111, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 111, 111, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 55, 55, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 53, 53, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 26, 26, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                5537856   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,657,226\n",
      "Trainable params: 5,657,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build conv2D CNN model, be careful with softmax and output layers is 10\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# define the input shape of Convolutional Neural Network\n",
    "# Your Code HERE\n",
    "input_shape = (img_height, img_width, 3)\n",
    "num_classes = train_labels[0].shape[0]\n",
    "\n",
    "print(f'Input shape : {input_shape}')\n",
    "\n",
    "\n",
    "# define the Convolutional Neural Network\n",
    "# Your Code HERE\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(10,activation =\"softmax\"))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "vlw2-kfL4_X-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 11:29:22.594723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - ETA: 0s - loss: 1.8312 - accuracy: 0.3561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 11:29:54.490796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 36s 138ms/step - loss: 1.8312 - accuracy: 0.3561 - val_loss: 1.1289 - val_accuracy: 0.6164\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 33s 125ms/step - loss: 0.5106 - accuracy: 0.8345 - val_loss: 0.6419 - val_accuracy: 0.8233\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 32s 122ms/step - loss: 0.1686 - accuracy: 0.9516 - val_loss: 0.4508 - val_accuracy: 0.8973\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 32s 122ms/step - loss: 0.0918 - accuracy: 0.9737 - val_loss: 0.5053 - val_accuracy: 0.8772\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 32s 122ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.5176 - val_accuracy: 0.8930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x436668c40>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model and training including the files of compile and fit\n",
    "#Your code \n",
    "#model.compile()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "#Train the model with training and validation set\n",
    "#model.fit()\n",
    "#, callbacks=[callback]\n",
    "model.fit(train_datagen, epochs=epochs, validation_data=val_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbsgqzIx4_X_"
   },
   "source": [
    "##Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "YiglYXTw4_YA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0789198875427246\n",
      "Test accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 11:32:06.973540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a testing dataset\n",
    "# Your Code HERE\n",
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "# Best so far \n",
    "# Test accuracy: 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDlS_Nk14_YB"
   },
   "source": [
    "## Part 2.3 - L1 Regularization. Please add L1 regularization setting in your Conv2D layer. Then, train your new model separately, and plot the training process including loss and accuracy. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "VRv7U-YG4_YB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (224, 224, 3)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 44, 44, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 42, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,650\n",
      "Trainable params: 38,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# please redefine your model with setting the L1 Regularization in the layer of Conv 2D\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "# Your code HERE\n",
    "\n",
    "input_shape = train_images[0].shape\n",
    "num_classes = train_labels[0].shape[0]\n",
    "\n",
    "print(f'Input shape : {input_shape}')\n",
    "\n",
    "\n",
    "# define the Convolutional Neural Network\n",
    "# Your Code HERE\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(10,activation =\"softmax\"))\n",
    "\n",
    "\n",
    "model_l1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 10:38:31.079384: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 102ms/step - loss: 2.3012 - accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.2000 - accuracy: 0.2188\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.1282 - accuracy: 0.2188\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.0668 - accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.9988 - accuracy: 0.2812\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.9279 - accuracy: 0.2812\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.8577 - accuracy: 0.4062\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.7606 - accuracy: 0.4375\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.6653 - accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.5750 - accuracy: 0.5625\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.4733 - accuracy: 0.5938\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.3527 - accuracy: 0.7188\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2363 - accuracy: 0.7188\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1170 - accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.9848 - accuracy: 0.7812\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.8750 - accuracy: 0.7812\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.7757 - accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6686 - accuracy: 0.8125\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5562 - accuracy: 0.8125\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.4729 - accuracy: 0.8438\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3927 - accuracy: 0.8750\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3098 - accuracy: 0.9062\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2356 - accuracy: 0.9375\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.1755 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.1323 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.1008 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0013 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fff40ca0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model and training including the files of compile and fit\n",
    "#Your code \n",
    "#model.compile()\n",
    "model_l1.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "#Train the model with training and validation set\n",
    "#model.fit()\n",
    "model_l1.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 10:38:41.264235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.750791072845459\n",
      "Test accuracy: 0.40625\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a testing dataset\n",
    "# Your Code HERE\n",
    "score = model_l1.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "# Best so far \n",
    "# Test accuracy: 0.625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IJJKvSZe-vP"
   },
   "source": [
    "## Part 2.4 - L2 Regularization. Please add L2 regularization setting in your Conv2D layer. Then, train your new model separately, and plot the training process including loss and accuracy. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "edJPfJsboprC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (256, 256, 3)\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_198 (Conv2D)         (None, 246, 246, 128)     46592     \n",
      "                                                                 \n",
      " max_pooling2d_197 (MaxPooli  (None, 49, 49, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (None, 43, 43, 64)        401472    \n",
      "                                                                 \n",
      " max_pooling2d_198 (MaxPooli  (None, 8, 8, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_200 (Conv2D)         (None, 4, 4, 32)          51232     \n",
      "                                                                 \n",
      " max_pooling2d_199 (MaxPooli  (None, 1, 1, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 1024)              33792     \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 812,586\n",
      "Trainable params: 812,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#please redefine your model and set the L2 Regularization in the layer of Conv 2D\n",
    "\n",
    "# Your code HERE\n",
    "\n",
    "# please redefine your model with setting the L1 Regularization in the layer of Conv 2D\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "# Your code HERE\n",
    "\n",
    "input_shape = train_images[0].shape\n",
    "num_classes = train_labels[0].shape[0]\n",
    "\n",
    "print(f'Input shape : {input_shape}')\n",
    "\n",
    "\n",
    "# define the Convolutional Neural Network\n",
    "# Your Code HERE\n",
    "model_l2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(5, 5)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(5, 5)),\n",
    "#         layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(3, 3)),\n",
    "        layers.Flatten(),\n",
    "#         layers.Dense(1024, activation='relu'),\n",
    "#         layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 10:25:48.535734: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 653ms/step - loss: 3.5879 - accuracy: 0.1875\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 692ms/step - loss: 3.3767 - accuracy: 0.1875\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 671ms/step - loss: 3.1470 - accuracy: 0.1875\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 3.0105 - accuracy: 0.1875\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 2.8567 - accuracy: 0.1875\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 659ms/step - loss: 2.7250 - accuracy: 0.1875\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 653ms/step - loss: 2.5650 - accuracy: 0.1875\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 2.4303 - accuracy: 0.3438\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 658ms/step - loss: 2.1898 - accuracy: 0.3750\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 682ms/step - loss: 2.1092 - accuracy: 0.4062\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 1.9264 - accuracy: 0.5312\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 1.5425 - accuracy: 0.6562\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 1.5934 - accuracy: 0.5625\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 665ms/step - loss: 1.2593 - accuracy: 0.6250\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 679ms/step - loss: 1.1486 - accuracy: 0.6562\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 0.8841 - accuracy: 0.7812\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 2s 680ms/step - loss: 0.7103 - accuracy: 0.8438\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 671ms/step - loss: 0.4666 - accuracy: 0.9688\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 0.4421 - accuracy: 0.9062\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 666ms/step - loss: 0.3431 - accuracy: 0.9688\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 707ms/step - loss: 0.3234 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 670ms/step - loss: 0.4545 - accuracy: 0.8750\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 670ms/step - loss: 0.4769 - accuracy: 0.9688\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 696ms/step - loss: 0.4258 - accuracy: 0.9375\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 666ms/step - loss: 0.2883 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 682ms/step - loss: 0.7528 - accuracy: 0.9375\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 696ms/step - loss: 0.3023 - accuracy: 0.9688\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 682ms/step - loss: 1.0736 - accuracy: 0.7812\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 665ms/step - loss: 0.3425 - accuracy: 0.9688\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 0.5147 - accuracy: 0.9062\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 681ms/step - loss: 0.4497 - accuracy: 0.9375\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 0.3405 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 0.3412 - accuracy: 0.9688\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 692ms/step - loss: 0.3012 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 681ms/step - loss: 0.2757 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 677ms/step - loss: 0.2578 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 654ms/step - loss: 0.2525 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 682ms/step - loss: 0.2516 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.2482 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 0.2452 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 653ms/step - loss: 0.2426 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 0.2395 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 0.2362 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 666ms/step - loss: 0.2325 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 0.2289 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 0.2254 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 680ms/step - loss: 0.2218 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 678ms/step - loss: 0.2183 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 679ms/step - loss: 0.2149 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 0.2116 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fff405b0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model and training including the files of compile and fit\n",
    "#Your code \n",
    "#model.compile()\n",
    "model_l2.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "#Train the model with training and validation set\n",
    "#model.fit()\n",
    "model_l2.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "nBjdyd9AdkRt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.761986017227173\n",
      "Test accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a testing dataset\n",
    "# Your Code HERE\n",
    "score = model_l2.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "# Best so far \n",
    "# Test accuracy: 0.625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1pu9bpP2S_R"
   },
   "source": [
    "## Part3 - ** only for 574 students **.\n",
    "1. Fine tune the well pre-trained model, Resnet 50, with different freeze layers. \n",
    "First,  load pre-trained resnet 50 from library.\n",
    "Second, Fine-tune the model to fit our project, 10-classes.\n",
    "Third,  freeze different layers, plot different training process with different frozen layers (at least three different layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hEVF4Oh02S_R"
   },
   "outputs": [],
   "source": [
    "# load pre-trained resnet 50 from libarary\n",
    "# your Code HERE\n",
    "resnet50 = keras.applications.ResNet50(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,719,498\n",
      "Trainable params: 131,786\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model to fit our project  \n",
    "# your Code HERE\n",
    "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
    "x = resnet50(inputs, training=False)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "y = keras.layers.Dense(64)(x)\n",
    "outputs = keras.layers.Dense(num_classes)(y)\n",
    "\n",
    "\n",
    "model_resnet50 = keras.Model(inputs, outputs)\n",
    "\n",
    "# define the freeze layers \n",
    "# your Code HERE\n",
    "model_resnet50.layers[1].trainable=False\n",
    "# model.layers[4].trainable=False\n",
    "\n",
    "\n",
    "# Please compile the new model\n",
    "#model.compile()\n",
    "model_resnet50.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model_resnet50.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RwCWmKKG1goQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:44:04.360082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s - loss: 2.4702 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:44:05.423487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 60 calls to <function Model.make_test_function.<locals>.test_function at 0x34dca5310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.4702 - accuracy: 0.2500 - val_loss: 2.6334 - val_accuracy: 0.0625\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.9985 - accuracy: 0.2500 - val_loss: 2.8862 - val_accuracy: 0.1250\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.8953 - accuracy: 0.4375 - val_loss: 3.2334 - val_accuracy: 0.1250\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 1.8378 - accuracy: 0.1875 - val_loss: 3.5303 - val_accuracy: 0.0625\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.7784 - accuracy: 0.3125 - val_loss: 3.7186 - val_accuracy: 0.0625\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.7362 - accuracy: 0.5000 - val_loss: 3.7949 - val_accuracy: 0.1875\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.6832 - accuracy: 0.5000 - val_loss: 3.8551 - val_accuracy: 0.1875\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.6478 - accuracy: 0.5000 - val_loss: 3.9599 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.6383 - accuracy: 0.6250 - val_loss: 4.0989 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.6220 - accuracy: 0.6250 - val_loss: 4.2483 - val_accuracy: 0.1875\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.5863 - accuracy: 0.5000 - val_loss: 4.4069 - val_accuracy: 0.1875\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 1.5523 - accuracy: 0.5000 - val_loss: 4.5558 - val_accuracy: 0.0625\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 1.5248 - accuracy: 0.5000 - val_loss: 4.6735 - val_accuracy: 0.0625\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.4984 - accuracy: 0.5000 - val_loss: 4.7637 - val_accuracy: 0.0625\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.4782 - accuracy: 0.6250 - val_loss: 4.8359 - val_accuracy: 0.1875\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.4639 - accuracy: 0.6250 - val_loss: 4.8884 - val_accuracy: 0.1875\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.4427 - accuracy: 0.6250 - val_loss: 4.9276 - val_accuracy: 0.1875\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.4157 - accuracy: 0.6250 - val_loss: 4.9614 - val_accuracy: 0.1250\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 1.3917 - accuracy: 0.6250 - val_loss: 4.9856 - val_accuracy: 0.0625\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.3695 - accuracy: 0.6250 - val_loss: 4.9968 - val_accuracy: 0.0625\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.3475 - accuracy: 0.6250 - val_loss: 5.0043 - val_accuracy: 0.0625\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.3292 - accuracy: 0.6250 - val_loss: 5.0197 - val_accuracy: 0.1875\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.3144 - accuracy: 0.6250 - val_loss: 5.0464 - val_accuracy: 0.1875\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.2967 - accuracy: 0.6250 - val_loss: 5.0856 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.2756 - accuracy: 0.6250 - val_loss: 5.1358 - val_accuracy: 0.1250\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.2557 - accuracy: 0.6250 - val_loss: 5.1854 - val_accuracy: 0.0625\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.2386 - accuracy: 0.6250 - val_loss: 5.2184 - val_accuracy: 0.0625\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.2224 - accuracy: 0.6250 - val_loss: 5.2300 - val_accuracy: 0.1250\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.2068 - accuracy: 0.6875 - val_loss: 5.2288 - val_accuracy: 0.1250\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.1919 - accuracy: 0.6875 - val_loss: 5.2266 - val_accuracy: 0.1250\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.1761 - accuracy: 0.6875 - val_loss: 5.2320 - val_accuracy: 0.1875\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.1592 - accuracy: 0.6875 - val_loss: 5.2465 - val_accuracy: 0.1250\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.1431 - accuracy: 0.6875 - val_loss: 5.2623 - val_accuracy: 0.1250\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.1285 - accuracy: 0.6875 - val_loss: 5.2693 - val_accuracy: 0.1250\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.1146 - accuracy: 0.6875 - val_loss: 5.2655 - val_accuracy: 0.1250\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.1009 - accuracy: 0.6875 - val_loss: 5.2581 - val_accuracy: 0.1250\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.0871 - accuracy: 0.6875 - val_loss: 5.2567 - val_accuracy: 0.1250\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.0729 - accuracy: 0.6875 - val_loss: 5.2667 - val_accuracy: 0.1875\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.0588 - accuracy: 0.6875 - val_loss: 5.2859 - val_accuracy: 0.1250\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.0456 - accuracy: 0.6875 - val_loss: 5.3045 - val_accuracy: 0.1875\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.0331 - accuracy: 0.6875 - val_loss: 5.3130 - val_accuracy: 0.1875\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.0206 - accuracy: 0.6875 - val_loss: 5.3106 - val_accuracy: 0.1875\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.0078 - accuracy: 0.6875 - val_loss: 5.3040 - val_accuracy: 0.1875\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.9953 - accuracy: 0.6875 - val_loss: 5.3012 - val_accuracy: 0.1875\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.9830 - accuracy: 0.6875 - val_loss: 5.3050 - val_accuracy: 0.1875\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.9710 - accuracy: 0.6875 - val_loss: 5.3121 - val_accuracy: 0.1875\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.9592 - accuracy: 0.6875 - val_loss: 5.3154 - val_accuracy: 0.1875\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.9477 - accuracy: 0.6875 - val_loss: 5.3112 - val_accuracy: 0.1875\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.9362 - accuracy: 0.6875 - val_loss: 5.3026 - val_accuracy: 0.1875\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.9248 - accuracy: 0.6875 - val_loss: 5.2972 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2939b09a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model with training and validation set\n",
    "#model.fit()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "#Train the model with training and validation set\n",
    "#model.fit()\n",
    "model_resnet50.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs,\n",
    "             validation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:44:23.462090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.64262580871582\n",
      "Test accuracy: 0.1875\n"
     ]
    }
   ],
   "source": [
    "score = model_resnet50.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,719,498\n",
      "Trainable params: 23,535,242\n",
      "Non-trainable params: 184,256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_resnet50.layers[1].trainable=True\n",
    "model_resnet50.layers[3].trainable=False\n",
    "\n",
    "model_resnet50.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "model_resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:58:10.136367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s - loss: 2.2375 - categorical_accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:58:13.533496: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 59 calls to <function Model.make_test_function.<locals>.test_function at 0x3690ce0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 6s 6s/step - loss: 2.2375 - categorical_accuracy: 0.3750 - val_loss: 4.4161 - val_categorical_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 1.7430 - categorical_accuracy: 0.4375 - val_loss: 4.8253 - val_categorical_accuracy: 0.1875\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 1.7964 - categorical_accuracy: 0.5000 - val_loss: 5.0004 - val_categorical_accuracy: 0.0625\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 1.9007 - categorical_accuracy: 0.4375 - val_loss: 4.3626 - val_categorical_accuracy: 0.0625\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 1.5796 - categorical_accuracy: 0.5000 - val_loss: 3.8498 - val_categorical_accuracy: 0.1875\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 1.2657 - categorical_accuracy: 0.5000 - val_loss: 3.8201 - val_categorical_accuracy: 0.1875\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 1.3111 - categorical_accuracy: 0.5000 - val_loss: 3.6680 - val_categorical_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 1.2126 - categorical_accuracy: 0.5625 - val_loss: 3.5691 - val_categorical_accuracy: 0.1875\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 1.1416 - categorical_accuracy: 0.6875 - val_loss: 3.6233 - val_categorical_accuracy: 0.1875\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 1.1479 - categorical_accuracy: 0.5000 - val_loss: 3.7198 - val_categorical_accuracy: 0.1875\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 1.1081 - categorical_accuracy: 0.5000 - val_loss: 3.8073 - val_categorical_accuracy: 0.1875\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.9920 - categorical_accuracy: 0.6250 - val_loss: 3.8759 - val_categorical_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.8523 - categorical_accuracy: 0.7500 - val_loss: 4.0150 - val_categorical_accuracy: 0.3125\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.8089 - categorical_accuracy: 0.6875 - val_loss: 4.2182 - val_categorical_accuracy: 0.3750\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.8202 - categorical_accuracy: 0.6875 - val_loss: 4.3517 - val_categorical_accuracy: 0.3125\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.7607 - categorical_accuracy: 0.6875 - val_loss: 4.5827 - val_categorical_accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.7137 - categorical_accuracy: 0.6875 - val_loss: 4.7757 - val_categorical_accuracy: 0.2500\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.6823 - categorical_accuracy: 0.7500 - val_loss: 4.7904 - val_categorical_accuracy: 0.1875\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.6336 - categorical_accuracy: 0.7500 - val_loss: 4.8007 - val_categorical_accuracy: 0.1875\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.6186 - categorical_accuracy: 0.6875 - val_loss: 4.8690 - val_categorical_accuracy: 0.1875\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.6192 - categorical_accuracy: 0.6875 - val_loss: 4.8576 - val_categorical_accuracy: 0.2500\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.5531 - categorical_accuracy: 0.7500 - val_loss: 4.9665 - val_categorical_accuracy: 0.2500\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.5095 - categorical_accuracy: 0.7500 - val_loss: 5.1264 - val_categorical_accuracy: 0.2500\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.4982 - categorical_accuracy: 0.7500 - val_loss: 5.1543 - val_categorical_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.4769 - categorical_accuracy: 0.7500 - val_loss: 5.0768 - val_categorical_accuracy: 0.2500\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.4459 - categorical_accuracy: 0.7500 - val_loss: 5.0487 - val_categorical_accuracy: 0.2500\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.4215 - categorical_accuracy: 0.7500 - val_loss: 5.1342 - val_categorical_accuracy: 0.3125\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.3914 - categorical_accuracy: 0.9375 - val_loss: 5.3586 - val_categorical_accuracy: 0.3125\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.3656 - categorical_accuracy: 1.0000 - val_loss: 5.6432 - val_categorical_accuracy: 0.3125\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.3433 - categorical_accuracy: 0.9375 - val_loss: 5.8452 - val_categorical_accuracy: 0.3125\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.3094 - categorical_accuracy: 1.0000 - val_loss: 5.9415 - val_categorical_accuracy: 0.3125\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.2777 - categorical_accuracy: 1.0000 - val_loss: 6.0547 - val_categorical_accuracy: 0.3125\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2581 - categorical_accuracy: 1.0000 - val_loss: 6.2825 - val_categorical_accuracy: 0.3125\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2265 - categorical_accuracy: 1.0000 - val_loss: 6.6354 - val_categorical_accuracy: 0.3125\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.1981 - categorical_accuracy: 1.0000 - val_loss: 6.9349 - val_categorical_accuracy: 0.3750\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.1831 - categorical_accuracy: 1.0000 - val_loss: 7.0433 - val_categorical_accuracy: 0.3125\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.1578 - categorical_accuracy: 1.0000 - val_loss: 7.0883 - val_categorical_accuracy: 0.3125\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.1389 - categorical_accuracy: 1.0000 - val_loss: 7.2681 - val_categorical_accuracy: 0.3125\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.1211 - categorical_accuracy: 1.0000 - val_loss: 7.5917 - val_categorical_accuracy: 0.3750\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.1001 - categorical_accuracy: 1.0000 - val_loss: 7.8771 - val_categorical_accuracy: 0.3750\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.0879 - categorical_accuracy: 1.0000 - val_loss: 7.9841 - val_categorical_accuracy: 0.3750\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.0751 - categorical_accuracy: 1.0000 - val_loss: 7.9768 - val_categorical_accuracy: 0.3750\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.0618 - categorical_accuracy: 1.0000 - val_loss: 8.0434 - val_categorical_accuracy: 0.3750\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.0534 - categorical_accuracy: 1.0000 - val_loss: 8.2717 - val_categorical_accuracy: 0.3750\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.0450 - categorical_accuracy: 1.0000 - val_loss: 8.6093 - val_categorical_accuracy: 0.3750\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.0365 - categorical_accuracy: 1.0000 - val_loss: 8.9598 - val_categorical_accuracy: 0.3750\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.0306 - categorical_accuracy: 1.0000 - val_loss: 9.2332 - val_categorical_accuracy: 0.3125\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.0261 - categorical_accuracy: 1.0000 - val_loss: 9.4027 - val_categorical_accuracy: 0.3750\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.0215 - categorical_accuracy: 1.0000 - val_loss: 9.5068 - val_categorical_accuracy: 0.3750\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.0173 - categorical_accuracy: 1.0000 - val_loss: 9.6185 - val_categorical_accuracy: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x38a9395e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_loss = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "model_resnet50.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs,\n",
    "             validation_data=(val_images, val_labels), callbacks=callback_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:58:49.100299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.74050521850586\n",
      "Test accuracy: 0.375\n"
     ]
    }
   ],
   "source": [
    "score = model_resnet50.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PA5_v3.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5f6b8115f497fb638a01b74ddbd33fce540e228ff9eb67bd803cc1958285b881"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py39_tf] *",
   "language": "python",
   "name": "conda-env-py39_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
